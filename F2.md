# 🧩 **F2 – Self-Service RAG & UX Flow (Functional Architecture)**

*Covers VS-3 (Self-Service RAG Builder & UX) + VS-7 (AI Literacy & Feedback Loop).*

Purpose → show how a **user or scientist builds, tests, and runs a retrieval-augmented generation (RAG)** workflow on AskRegn-AI — and how that usage loops back into literacy, governance, and improvement.

---

## 🟦 **Canvas Specification**

* **Orientation:** Landscape 16 × 9
* **Flow direction:** Left → Right (primary builder → deployment → feedback)
* **Feedback loop:** Right → Left for learning & policy update
* **Color cues:** Blue = user/data flow Orange = governance feedback Grey = data stores Green = reusable models / tools

---

## 🔹 **Functional Zones (draw them left → right like a storyboard)**

---

### **1️⃣ Builder Workspace (Entry Zone – User Plane)**

*(Left edge of slide)*

**Boxes (top → bottom stack):**

1. **AskRegn-AI Builder UI**

   * “No/Low-Code RAG Builder (Wizard + Advanced Mode)”
   * *Users define source, prompt, embedding model, evaluation rules.*

2. **Auth & Project Context Service**

   * “OKTA SSO → Workspace Context (Org/Team Tagging)”

3. **Config Template Repo**

   * “Pre-built templates (GitHub / Registry) for common tasks.”

➡ **Output arrow →** Configuration JSON to RAG Pipeline Builder

> **Deliverables:** VS-3 D1 (Self-Service UI), VS-3 D2 (Template Library)

---

### **2️⃣ Data Ingestion & Preparation Corridor**

*(Mid-left section, wider horizontal band)*

**Flow:** Data Sources (bottom) → ETL → Chunking → Embeddings → Vector DB

**Sub-boxes (left → right):**

* **Source Connectors** (SharePoint, Confluence, Veeva, PubMed APIs)
* **ETL Pipelines** (Dataiku / Databricks) → cleaning, metadata tagging
* **Chunker & Embedder Engine** (LlamaIndex + OpenAI Embeddings)
* **Vector Store** (Milvus / Pinecone adapter)

Small upward arrow from Vector Store → **Lineage Graph (Neo4j)**
→ annotation: “Lineage captured for audit & reuse.”

> **Deliverables:** VS-3 D3 (Data Connector Framework), VS-6 D1 (Lineage Capture)

---

### **3️⃣ RAG Pipeline Execution (Engine Core)**

*(Center of slide – large rounded rectangle)*

Inside, show **4 modules** arranged left → right with arrows:

1. **Retriever Service** → “Queries Milvus vectors using semantic search.”
2. **Context Assembler** → “Combines top-k snippets + metadata into prompt.”
3. **LLM Invoker** → “Calls Gateway (LLM Routing + Policy Control).”
4. **Response Composer** → “Generates answer / summary / draft.”

Below these, a horizontal sub-bar:
**“Evaluator & Metrics Collector – BLEU, ROUGE, Accuracy, Cost”** → feeds into FinOps + AI Literacy.

> **Deliverables:** VS-3 D4 (Execution Engine), VS-2 D3 (Evaluator reuse)

---

### **4️⃣ Publishing & User Interaction Layer**

*(Mid-right section)*

**Boxes stacked vertically:**

* **Deployed Companion Bot** – “Hosted RAG App (Next.js Widget + FastAPI Backend).”
* **Feedback Panel / Rating Widget** – “User thumbs-up/down + comment → stored as training signal.”
* **Dashboard & Reports** – “Usage, cost, accuracy analytics → PowerBI / Grafana.”

Upward arrow to **AI Literacy Portal** (top right corner):
“Tutorials auto-updated from user cases.”

> **Deliverables:** VS-7 D1 (Feedback Portal), VS-3 D5 (Dashboard Analytics)

---

### **5️⃣ Governance & Continuous Learning Loop**

*(Orange feedback arc running from right to left along bottom)*

* **Governance Analyzer** → reads user feedback + eval scores.
* **Model Risk Profiler** → rates RAG runs on accuracy vs policy.
* **Policy Update Push** → updates Gateway rules and Template Repo.

Annotation on arc: *“RFP §5.4.6 – Continuous improvement and AI Literacy feedback.”*

> **Deliverables:** VS-7 D2 (Responsible AI Training Cycle), VS-1 Link (Policy Update Integration)

---

## 🔄 **Numbered Functional Steps (to label arrows)**

1️⃣ User launches Builder → creates project (template selected).
2️⃣ Sources connected → data ingested and chunked.
3️⃣ Embeddings generated → stored in Milvus + lineage logged.
4️⃣ User runs RAG pipeline → retriever → LLM → response.
5️⃣ Evaluator scores result → metrics to dashboard.
6️⃣ User provides feedback → AI Literacy Portal updates.
7️⃣ Governance Analyzer reviews results → policy/template update to Gateway & Repo.

---

## 🧠 **Footer Text**

> *Functional view covering VS-3 (Self-Service RAG Builder) and VS-7 (AI Literacy & Feedback): demonstrates how enterprise users ingest data, build RAG apps, evaluate outputs, and feed governance and training loops per RFP §5.4.3 and §5.4.6.*

---

### **Visual Design Tips**

* Make the **RAG Pipeline Execution** box dominant (center).
* Use bottom stream for data ingestion and top loop for literacy feedback.
* Color legend (bottom-right):

  * Blue = user/data flow 
  * Grey = data stores 
  * Green = reusable models / tools 
  * Orange = governance feedback.
* Include mini-list “Components Reused from Component Architecture:” UI Builder, ETL Pipelines, Chunker, Embedder, Milvus, Gateway API, Evaluator, Dashboard, Governance Analyzer.

---

### ✅ **Outcome**

A single dynamic slide that tells the **end-to-end story of the RAG workflow** — from user creation to model feedback — while satisfying **all deliverables** of **VS-3 and VS-7** and tying back to components defined in your Component Architecture.
